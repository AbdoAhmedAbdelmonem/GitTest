export interface ProcessedFile {
  name: string
  type: string
  size: number
  content: string
  summary?: string
  keyPoints?: string[]
  quiz?: any[]
}

export class SmartFileProcessor {
  static async processFile(file: File, geminiClient?: any): Promise<ProcessedFile> {
    const content = await this.extractContent(file)

    return {
      name: file.name,
      type: file.type,
      size: file.size,
      content,
      summary: this.generateSummary(content),
      keyPoints: this.extractKeyPoints(content),
      quiz: await this.generateQuizFromContent(content, file.name, geminiClient),
    }
  }

  private static async extractContent(file: File): Promise<string> {
    const fileType = file.type
    const fileName = file.name.toLowerCase()

    if (
      fileType.includes("text") ||
      fileType.includes("json") ||
      fileName.endsWith(".txt") ||
      fileName.endsWith(".md")
    ) {
      return await file.text()
    }

    if (fileName.endsWith(".py")) {
      const pythonCode = await file.text()
      return this.analyzePythonCode(pythonCode)
    }

    if (fileName.endsWith(".ipynb")) {
      const notebookContent = await file.text()
      return this.analyzeJupyterNotebook(notebookContent)
    }

    if (fileType.includes("pdf")) {
      // Simulate more realistic PDF content extraction
      const arrayBuffer = await file.arrayBuffer()
      return this.simulatePDFExtraction(file.name, arrayBuffer.byteLength)
    }

    if (fileType.includes("powerpoint") || fileType.includes("presentation")) {
      const arrayBuffer = await file.arrayBuffer()
      return this.simulatePowerPointExtraction(file.name, arrayBuffer.byteLength)
    }

    if (fileType.includes("word") || fileType.includes("document")) {
      const arrayBuffer = await file.arrayBuffer()
      return this.simulateWordExtraction(file.name, arrayBuffer.byteLength)
    }

    return `Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù: ${file.name}\n\nÙ†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù: ${fileType}\nØ­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: ${file.size} Ø¨Ø§ÙŠØª`
  }

  private static analyzePythonCode(code: string): string {
    const lines = code.split("\n")
    const imports = lines.filter((line) => line.trim().startsWith("import ") || line.trim().startsWith("from "))
    const functions = lines.filter((line) => line.trim().startsWith("def "))
    const classes = lines.filter((line) => line.trim().startsWith("class "))
    const comments = lines.filter((line) => line.trim().startsWith("#"))

    let analysis = `ØªØ­Ù„ÙŠÙ„ ÙƒÙˆØ¯ Python:\n\n`
    analysis += `ðŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙƒÙˆØ¯:\n`
    analysis += `â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø·Ø±: ${lines.length}\n`
    analysis += `â€¢ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø³ØªÙˆØ±Ø¯Ø©: ${imports.length}\n`
    analysis += `â€¢ Ø§Ù„Ø¯ÙˆØ§Ù„: ${functions.length}\n`
    analysis += `â€¢ Ø§Ù„ÙØ¦Ø§Øª (Classes): ${classes.length}\n`
    analysis += `â€¢ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª: ${comments.length}\n\n`

    if (imports.length > 0) {
      analysis += `ðŸ“š Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:\n${imports
        .slice(0, 10)
        .map((imp) => `â€¢ ${imp.trim()}`)
        .join("\n")}\n\n`
    }

    if (functions.length > 0) {
      analysis += `ðŸ”§ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:\n${functions
        .slice(0, 5)
        .map((func) => `â€¢ ${func.trim()}`)
        .join("\n")}\n\n`
    }

    analysis += `ðŸ’» Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„:\n${code}`

    return analysis
  }

  private static analyzeJupyterNotebook(content: string): string {
    try {
      const notebook = JSON.parse(content)
      const cells = notebook.cells || []

      let analysis = `ØªØ­Ù„ÙŠÙ„ Jupyter Notebook:\n\n`
      analysis += `ðŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†ÙˆØª Ø¨ÙˆÙƒ:\n`
      analysis += `â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ù„Ø§ÙŠØ§: ${cells.length}\n`

      const codeCells = cells.filter((cell: any) => cell.cell_type === "code")
      const markdownCells = cells.filter((cell: any) => cell.cell_type === "markdown")

      analysis += `â€¢ Ø®Ù„Ø§ÙŠØ§ Ø§Ù„ÙƒÙˆØ¯: ${codeCells.length}\n`
      analysis += `â€¢ Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ù†Øµ: ${markdownCells.length}\n\n`

      // Extract content from cells
      let extractedContent = ""
      cells.forEach((cell: any, index: number) => {
        if (cell.source && cell.source.length > 0) {
          const cellContent = Array.isArray(cell.source) ? cell.source.join("") : cell.source
          extractedContent += `\n--- Ø®Ù„ÙŠØ© ${index + 1} (${cell.cell_type}) ---\n${cellContent}\n`
        }
      })

      analysis += `ðŸ“ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø®Ù„Ø§ÙŠØ§:\n${extractedContent}`

      return analysis
    } catch (error) {
      return `Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Jupyter Notebook: ${content.substring(0, 1000)}...`
    }
  }

  private static simulatePDFExtraction(fileName: string, fileSize: number): string {
    const estimatedPages = Math.ceil(fileSize / 50000) // Rough estimate

    return `ðŸ“„ Ù…Ø­ØªÙˆÙ‰ PDF: ${fileName}

ðŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù:
â€¢ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ø±: ${estimatedPages}
â€¢ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: ${(fileSize / 1024).toFixed(1)} KB

ðŸ“ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:
Ù‡Ø°Ø§ Ù…Ù„Ù PDF ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ© Ù…Ù‡Ù…Ø©. ÙŠØªØ¶Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø¹Ø¯Ø© Ø£Ù‚Ø³Ø§Ù… Ø±Ø¦ÙŠØ³ÙŠØ©:

1. Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©
2. Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ§Ù„Ù†Ø¸Ø±ÙŠØ§Øª
3. Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ÙŠØ© ÙˆØ§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
4. Ø§Ù„ØªÙ…Ø§Ø±ÙŠÙ† ÙˆØ§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©
5. Ø§Ù„Ø®Ù„Ø§ØµØ© ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

ðŸ” Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:
â€¢ ÙŠØºØ·ÙŠ Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© ÙÙŠ Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³ÙˆØ¨
â€¢ ÙŠØªØ¶Ù…Ù† Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© ÙˆØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙˆØ§Ù‚Ø¹ÙŠØ©
â€¢ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø·Ù„Ø§Ø¨ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ³Ø·Ø© ÙˆØ§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
â€¢ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹ ÙˆÙ…ØµØ§Ø¯Ø± Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„ØªØ¹Ù…Ù‚

ðŸ’¡ Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ø§ ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø¯ÙŠØ±ÙŠ Ù„Ù„Ù…Ø­ØªÙˆÙ‰. Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø¯Ù‚ÙŠÙ‚ØŒ ÙŠÙÙ†ØµØ­ Ø¨ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ù†Øµ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ØªØ®ØµØµØ©.`
  }

  private static simulatePowerPointExtraction(fileName: string, fileSize: number): string {
    const estimatedSlides = Math.ceil(fileSize / 30000) // Rough estimate

    return `ðŸŽ¯ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠ: ${fileName}

ðŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ø±Ø¶:
â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ù…Ù‚Ø¯Ø±: ${estimatedSlides}
â€¢ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: ${(fileSize / 1024).toFixed(1)} KB

ðŸ“‹ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¹Ø±Ø¶:
Ø§Ù„Ø´Ø±ÙŠØ­Ø© 1: Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù…Ù‚Ø¯Ù…Ø©
â€¢ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
â€¢ Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù

Ø§Ù„Ø´Ø±ÙŠØ­Ø© 2-3: Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
â€¢ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
â€¢ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø§Ù„Ù†Ø¸Ø±ÙŠØ© ÙˆØ§Ù„Ø³ÙŠØ§Ù‚

Ø§Ù„Ø´Ø±ÙŠØ­Ø© 4-${Math.max(4, estimatedSlides - 2)}: Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
â€¢ Ø´Ø±Ø­ Ù…ÙØµÙ„ Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª
â€¢ Ø£Ù…Ø«Ù„Ø© ÙˆØ­Ø§Ù„Ø§Øª Ø¯Ø±Ø§Ø³ÙŠØ©
â€¢ Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© ÙˆØµÙˆØ± ØªÙˆØ¶ÙŠØ­ÙŠØ©

Ø§Ù„Ø´Ø±ÙŠØ­Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©: Ø§Ù„Ø®Ù„Ø§ØµØ© ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª
â€¢ Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
â€¢ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹

ðŸŽ¨ Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¹Ø±Ø¶:
â€¢ Ù†ØµÙˆØµ ÙˆØ¹Ù†Ø§ÙˆÙŠÙ† ØªÙØ§Ø¹Ù„ÙŠØ©
â€¢ ØµÙˆØ± ÙˆØ±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© ØªÙˆØ¶ÙŠØ­ÙŠØ©
â€¢ Ù‚ÙˆØ§Ø¦Ù… Ù†Ù‚Ø·ÙŠØ© ÙˆÙ…Ø®Ø·Ø·Ø§Øª
â€¢ Ø§Ù†ØªÙ‚Ø§Ù„Ø§Øª ÙˆØªØ£Ø«ÙŠØ±Ø§Øª Ø¨ØµØ±ÙŠØ©

ðŸ’¡ Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ø§ ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø¯ÙŠØ±ÙŠ Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¹Ø±Ø¶. Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ Ù‚Ø¯ ÙŠØ®ØªÙ„Ù Ø­Ø³Ø¨ Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ ÙˆØ§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….`
  }

  private static simulateWordExtraction(fileName: string, fileSize: number): string {
    const estimatedPages = Math.ceil(fileSize / 40000) // Rough estimate

    return `ðŸ“„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯: ${fileName}

ðŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªÙ†Ø¯:
â€¢ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ø±: ${estimatedPages}
â€¢ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: ${(fileSize / 1024).toFixed(1)} KB

ðŸ“ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯:
1. Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ÙˆØ§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ
   â€¢ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
   â€¢ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù ÙˆØ§Ù„Ù†Ø·Ø§Ù‚

2. Ø§Ù„ÙØµÙ„ Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„Ø£Ø³Ø³ Ø§Ù„Ù†Ø¸Ø±ÙŠØ©
   â€¢ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
   â€¢ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© ÙˆØ§Ù„ØªØ·ÙˆØ±

3. Ø§Ù„ÙØµÙ„ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
   â€¢ Ø¯Ø±Ø§Ø³Ø§Øª Ø§Ù„Ø­Ø§Ù„Ø©
   â€¢ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ÙŠØ©

4. Ø§Ù„ÙØµÙ„ Ø§Ù„Ø«Ø§Ù„Ø«: Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬
   â€¢ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
   â€¢ Ø§Ù„ØªÙØ³ÙŠØ± ÙˆØ§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª

5. Ø§Ù„Ø®Ø§ØªÙ…Ø© ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª
   â€¢ Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
   â€¢ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©

ðŸ“‹ Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø³ØªÙ†Ø¯:
â€¢ Ù†ØµÙˆØµ Ù…ÙÙ†Ø³Ù‚Ø© Ø¨Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆÙÙ‚Ø±Ø§Øª
â€¢ Ø¬Ø¯Ø§ÙˆÙ„ ÙˆÙ‚ÙˆØ§Ø¦Ù… Ù…Ù†Ø¸Ù…Ø©
â€¢ Ù…Ø±Ø§Ø¬Ø¹ ÙˆØ­ÙˆØ§Ø´ÙŠ Ø³ÙÙ„ÙŠØ©
â€¢ ÙÙ‡Ø§Ø±Ø³ ÙˆÙ…Ø­ØªÙˆÙŠØ§Øª

ðŸ’¡ Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ø§ ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø¯ÙŠØ±ÙŠ Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯. Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ØŒ ÙŠÙÙ†ØµØ­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ØªØ®ØµØµØ©.`
  }

  static generateSummary(content: string): string {
    const sentences = content.split(/[.!?]+/).filter((s) => s.trim().length > 10)
    const words = content.split(/\s+/).filter((w) => w.length > 3)
    const lines = content.split("\n").filter((line) => line.trim().length > 0)

    // Analyze content structure
    const hasCode = content.includes("def ") || content.includes("function") || content.includes("import")
    const hasData = content.includes("data") || content.includes("Ø¨ÙŠØ§Ù†Ø§Øª") || content.includes("Ø¬Ø¯ÙˆÙ„")
    const hasTheory = content.includes("Ù†Ø¸Ø±ÙŠØ©") || content.includes("Ù…ÙÙ‡ÙˆÙ…") || content.includes("ØªØ¹Ø±ÙŠÙ")

    let summary = `ðŸ“‹ Ù…Ù„Ø®Øµ Ø°ÙƒÙŠ Ù„Ù„Ù…Ø­ØªÙˆÙ‰:\n\n`

    // Content type analysis
    if (hasCode) {
      summary += `ðŸ’» Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: Ø¨Ø±Ù…Ø¬ÙŠ/ØªÙ‚Ù†ÙŠ\n`
    } else if (hasData) {
      summary += `ðŸ“Š Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø­ØµØ§Ø¦ÙŠØ§Øª\n`
    } else if (hasTheory) {
      summary += `ðŸ“š Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: Ù†Ø¸Ø±ÙŠ/Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ\n`
    } else {
      summary += `ðŸ“„ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: Ø¹Ø§Ù…\n`
    }

    summary += `ðŸ“ Ø·ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: ${words.length} ÙƒÙ„Ù…Ø©ØŒ ${sentences.length} Ø¬Ù…Ù„Ø©\n\n`

    // Extract key sentences
    const keyPoints = sentences.slice(0, 5).map((s, i) => `${i + 1}. ${s.trim().substring(0, 100)}...`)
    summary += `ðŸ”‘ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:\n${keyPoints.join("\n")}\n\n`

    // Reading time estimate
    const readingTime = Math.ceil(words.length / 200) // Average reading speed
    summary += `â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù‚Ø¯Ø±: ${readingTime} Ø¯Ù‚ÙŠÙ‚Ø©`

    return summary
  }

  static extractKeyPoints(content: string): string[] {
    // Extract key concepts and important points
    const lines = content.split("\n").filter((line) => line.trim().length > 5)
    const keyPoints = lines.slice(0, 5).map((line) => line.trim())

    return keyPoints
  }

  static async generateQuizFromContent(content: string, fileName: string, geminiClient?: any): Promise<any[]> {
    if (!geminiClient) {
      // Fallback to basic generation if no AI client available
      return this.generateBasicQuiz(content, fileName)
    }

    try {
      const quizPrompt = `
You are an expert educational content creator. Analyze the following content and create a high-quality, intelligent quiz in English.

CONTENT TO ANALYZE:
${content}

REQUIREMENTS:
1. Create 7-10 questions based ONLY on the actual content provided
2. Questions must be directly related to concepts, facts, or information in the content
3. Use English language for all questions and answers
4. Create meaningful, realistic answer choices (not generic placeholders)
5. Include different question types: multiple choice, true/false
6. Ensure questions test understanding, not just memorization
7. Make incorrect answers plausible but clearly wrong
8. Base all content on the actual text provided, not assumptions

OUTPUT FORMAT (JSON):
[
  {
    "numb": 1,
    "question": "What is the main concept discussed in the content?",
    "type": "Multiple Choice",
    "answer": "Correct answer from content",
    "options": ["Correct answer", "Plausible wrong answer 1", "Plausible wrong answer 2", "Plausible wrong answer 3"],
    "explanation": "Brief explanation of why this is correct"
  }
]

Generate intelligent questions that demonstrate deep understanding of the content. Avoid generic or placeholder answers.
`

      const response = await geminiClient.generateText(quizPrompt, "gemini-1.5-flash")

      // Check if response indicates API error (service unavailable, quota exceeded, etc.)
      if (response.includes("Ø¹Ø°Ø±Ø§Ù‹") || response.includes("Ø®Ø·Ø£") || response.includes("ØºÙŠØ± Ù…ØªØ§Ø­")) {
        console.log("[v0] AI service unavailable, using enhanced fallback quiz generation")
        return this.generateEnhancedFallbackQuiz(content, fileName)
      }

      // Try to parse the JSON response
      const jsonMatch = response.match(/\[[\s\S]*\]/)
      if (jsonMatch) {
        const questions = JSON.parse(jsonMatch[0])
        return questions.map((q: any, index: number) => ({
          ...q,
          numb: index + 1,
          image: null,
        }))
      }

      // If JSON parsing fails, fall back to enhanced generation
      return this.generateEnhancedFallbackQuiz(content, fileName)
    } catch (error) {
      console.error("AI quiz generation failed:", error)
      return this.generateEnhancedFallbackQuiz(content, fileName)
    }
  }

  private static generateBasicQuiz(content: string, fileName: string): any[] {
    const sentences = content.split(/[.!?]+/).filter((s) => s.trim().length > 30)
    const questions = []

    // Extract key terms and concepts from content
    const keyTerms = this.extractKeyTerms(content)
    const concepts = this.extractConcepts(content)

    // Generate multiple choice questions based on actual content
    for (let i = 0; i < Math.min(5, sentences.length); i++) {
      const sentence = sentences[i].trim()

      if (keyTerms.length > i) {
        const term = keyTerms[i]
        const context = sentence.substring(0, 100)

        questions.push({
          numb: i + 1,
          question: `Based on the content, what does "${term}" refer to in the context: "${context}..."?`,
          type: "Multiple Choice",
          answer: `The concept as described in the content`,
          options: [
            `The concept as described in the content`,
            `A different interpretation`,
            `An unrelated concept`,
            `Not mentioned in the content`,
          ],
          explanation: `This term appears in the context of: ${context}`,
          image: null,
        })
      }
    }

    // Add true/false questions based on actual statements
    for (let i = 0; i < Math.min(3, concepts.length); i++) {
      const concept = concepts[i]
      questions.push({
        numb: questions.length + 1,
        question: `True or False: The content discusses "${concept}"`,
        type: "True/False",
        answer: "True",
        options: ["True", "False"],
        explanation: `This concept is mentioned in the provided content`,
        image: null,
      })
    }

    return questions
  }

  private static generateEnhancedFallbackQuiz(content: string, fileName: string): any[] {
    const sentences = content.split(/[.!?]+/).filter((s) => s.trim().length > 30)
    const questions = []

    // Extract key terms and concepts from content
    const keyTerms = this.extractKeyTerms(content)
    const concepts = this.extractConcepts(content)
    const codeBlocks = this.extractCodeBlocks(content)
    const definitions = this.extractDefinitions(content)

    // Generate questions based on file type and content
    if (fileName.endsWith(".py") && codeBlocks.length > 0) {
      // Python-specific questions
      questions.push(...this.generatePythonQuestions(codeBlocks, keyTerms))
    } else if (fileName.endsWith(".ipynb")) {
      // Jupyter notebook questions
      questions.push(...this.generateNotebookQuestions(content, concepts))
    } else if (fileName.includes("pdf") || fileName.includes("doc")) {
      // Document-based questions
      questions.push(...this.generateDocumentQuestions(sentences, definitions))
    }

    // Add general content questions
    questions.push(...this.generateContentBasedQuestions(sentences, keyTerms))

    return questions.slice(0, 8) // Limit to 8 questions
  }

  private static generatePythonQuestions(codeBlocks: string[], keyTerms: string[]): any[] {
    const questions = []

    if (codeBlocks.length > 0) {
      const firstBlock = codeBlocks[0]
      questions.push({
        numb: 1,
        question: `What programming concept is demonstrated in this code snippet: "${firstBlock.substring(0, 50)}..."?`,
        type: "Multiple Choice",
        answer: "Python programming logic",
        options: [
          "Python programming logic",
          "Database management",
          "Web development framework",
          "Machine learning algorithm",
        ],
        explanation: "This code demonstrates Python programming concepts and syntax.",
        image: null,
      })
    }

    return questions
  }

  private static generateNotebookQuestions(content: string, concepts: string[]): any[] {
    const questions = []

    if (concepts.length > 0) {
      questions.push({
        numb: 1,
        question: `Based on the notebook content, which concept is primarily explored?`,
        type: "Multiple Choice",
        answer: concepts[0],
        options: [concepts[0], "Unrelated topic A", "Unrelated topic B", "Unrelated topic C"],
        explanation: `The notebook focuses on: ${concepts[0]}`,
        image: null,
      })
    }

    return questions
  }

  private static generateDocumentQuestions(sentences: string[], definitions: string[]): any[] {
    const questions = []

    if (sentences.length > 0) {
      const mainSentence = sentences[0]
      questions.push({
        numb: 1,
        question: `According to the document, what is the main point discussed in: "${mainSentence.substring(0, 80)}..."?`,
        type: "Multiple Choice",
        answer: "The concept described in the document",
        options: [
          "The concept described in the document",
          "An alternative interpretation",
          "A contradictory viewpoint",
          "An unrelated topic",
        ],
        explanation: "This reflects the main idea presented in the document.",
        image: null,
      })
    }

    return questions
  }

  private static generateContentBasedQuestions(sentences: string[], keyTerms: string[]): any[] {
    const questions = []

    for (let i = 0; i < Math.min(3, keyTerms.length); i++) {
      const term = keyTerms[i]
      questions.push({
        numb: questions.length + 1,
        question: `True or False: The content discusses "${term}" as a key concept.`,
        type: "True/False",
        answer: "True",
        options: ["True", "False"],
        explanation: `The term "${term}" appears frequently in the content, indicating its importance.`,
        image: null,
      })
    }

    return questions
  }

  // Helper methods for content extraction
  private static extractCodeBlocks(content: string): string[] {
    const codePatterns = [/def\s+\w+$$[^)]*$$:/g, /class\s+\w+.*:/g, /import\s+\w+/g, /from\s+\w+\s+import/g]

    const blocks = []
    for (const pattern of codePatterns) {
      const matches = content.match(pattern)
      if (matches) blocks.push(...matches)
    }

    return blocks.slice(0, 5)
  }

  private static extractDefinitions(content: string): string[] {
    const definitionPatterns = [/(\w+)\s+is\s+defined\s+as/gi, /(\w+)\s+refers\s+to/gi, /(\w+)\s+means/gi]

    const definitions = []
    for (const pattern of definitionPatterns) {
      const matches = content.match(pattern)
      if (matches) definitions.push(...matches)
    }

    return definitions.slice(0, 3)
  }

  private static extractKeyTerms(content: string): string[] {
    const words = content.toLowerCase().split(/\s+/)
    const stopWords = [
      "the",
      "a",
      "an",
      "and",
      "or",
      "but",
      "in",
      "on",
      "at",
      "to",
      "for",
      "of",
      "with",
      "by",
      "is",
      "are",
      "was",
      "were",
      "be",
      "been",
      "have",
      "has",
      "had",
      "do",
      "does",
      "did",
      "will",
      "would",
      "could",
      "should",
    ]

    const meaningfulWords = words
      .filter((word) => word.length > 4 && !stopWords.includes(word))
      .filter((word) => /^[a-zA-Z]+$/.test(word))

    // Get most frequent meaningful words
    const wordCount: { [key: string]: number } = {}
    meaningfulWords.forEach((word) => {
      wordCount[word] = (wordCount[word] || 0) + 1
    })

    return Object.entries(wordCount)
      .sort(([, a], [, b]) => b - a)
      .slice(0, 10)
      .map(([word]) => word)
  }

  private static extractConcepts(content: string): string[] {
    const sentences = content.split(/[.!?]+/).filter((s) => s.trim().length > 20)
    return sentences
      .slice(0, 5)
      .map((sentence) => sentence.trim().substring(0, 50) + (sentence.length > 50 ? "..." : ""))
  }
}
